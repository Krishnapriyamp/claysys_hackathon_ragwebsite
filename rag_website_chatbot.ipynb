{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_REAL_KEY\""
      ],
      "metadata": {
        "id": "2ik9hsAeYKxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "print(\"API configured successfully\")"
      ],
      "metadata": {
        "id": "SLJCDeEVYfkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-genai"
      ],
      "metadata": {
        "id": "itfJDEQEY1g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in client.models.list():\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "mrbc23j9Y5Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Explain machine learning in simple words\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "kG8FAuExZvmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OffdL3CO_jq"
      },
      "outputs": [],
      "source": [
        "#Install Libraries\n",
        "!pip install requests beautifulsoup4 sentence-transformers faiss-cpu openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vTfdwd77PNiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step1::Web Scraping\n",
        "url = \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Extract only main content area\n",
        "content = soup.find(\"div\", {\"id\": \"mw-content-text\"})\n",
        "\n",
        "# Remove unwanted tags\n",
        "for script in content([\"script\", \"style\", \"sup\", \"table\"]):\n",
        "    script.decompose()\n",
        "\n",
        "text = content.get_text(separator=\" \")\n",
        "\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "id": "oOqgAM3cPVZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step2::text into chunks\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    chunks = []\n",
        "    for i in range(0, len(text), chunk_size):\n",
        "        chunks.append(text[i:i+chunk_size])\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(text)\n",
        "\n",
        "print(\"Total chunks:\", len(chunks))\n",
        "print(\"First chunk preview:\\n\", chunks[0])"
      ],
      "metadata": {
        "id": "dpEh2F3-RDB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step3::Generate Embeddings\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Convert chunks into embeddings\n",
        "embeddings = model.encode(chunks)\n",
        "\n",
        "print(\"Embedding shape:\", embeddings.shape)"
      ],
      "metadata": {
        "id": "9iHbmBKpRqBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step4::Create FAISS Vector Database\n",
        "dimension = embeddings.shape[1]\n",
        "\n",
        "# Create FAISS index\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Add embeddings to index\n",
        "index.add(np.array(embeddings))\n",
        "\n",
        "print(\"Total vectors stored in FAISS:\", index.ntotal)"
      ],
      "metadata": {
        "id": "Sb5dc6bKSD2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 5::Ask Question & Retrieve\n",
        "question = \"What is machine learning?\"\n",
        "\n",
        "# Convert question to embedding\n",
        "question_embedding = model.encode([question])\n",
        "\n",
        "# Retrieve top 3 similar chunks\n",
        "k = 3\n",
        "distances, indices = index.search(np.array(question_embedding), k)\n",
        "\n",
        "retrieved_chunks = [chunks[i] for i in indices[0]]\n",
        "\n",
        "print(\"Retrieved Chunks:\\n\")\n",
        "\n",
        "for i, chunk in enumerate(retrieved_chunks):\n",
        "    print(f\"Chunk {i+1}:\\n\")\n",
        "    print(chunk[:500])\n",
        "    print(\"\\n--------------------\\n\")"
      ],
      "metadata": {
        "id": "h82_JKAISOWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "b4MaJi--YJMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question)"
      ],
      "metadata": {
        "id": "1LeQkZW4aiTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6::Connect to OpenAI\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Configure API\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# Load model\n",
        "model_llm = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "# Combine retrieved chunks\n",
        "context = \" \".join(retrieved_chunks)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Answer the question using ONLY the context below.\n",
        "If the answer is not in the context, say you don't know.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "response = model_llm.generate_content(prompt)\n",
        "\n",
        "print(\"Final Answer:\\n\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "sxvmUjAJaehz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sources:\")\n",
        "for i, chunk in enumerate(retrieved_chunks):\n",
        "    print(f\"Source chunk {i+1}\")"
      ],
      "metadata": {
        "id": "g4648q7JbFt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}